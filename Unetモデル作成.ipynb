{"cells":[{"cell_type":"markdown","metadata":{"id":"DU9PzV6S_22Z"},"source":["### ライブラリのインポート"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xlZPaQ7B_22Z","executionInfo":{"status":"ok","timestamp":1688032941418,"user_tz":-540,"elapsed":5894,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["#使わないものも含む\n","import os, glob\n","from google.colab import drive\n","import random\n","from typing import Tuple, List, Dict\n","import cv2\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.nn import Linear,ReLU,CrossEntropyLoss,Sequential,Conv2d,MaxPool2d,Module,Softmax,BatchNorm2d,Dropout\n","from torch.optim import Adam,SGD\n","from torchvision import transforms,utils\n","from torch.utils.data import Dataset, DataLoader,random_split\n","\n","import pandas as pd\n","import time\n","import copy\n","from collections import defaultdict\n","import shutil\n","from skimage import io,transform\n","from PIL  import Image\n","import matplotlib.pyplot as plt\n","import albumentations as A\n","from tqdm import tqdm as tqdm\n","from albumentations import ShiftScaleRotate,Normalize,Resize,Compose,GaussNoise\n","from albumentations.pytorch import ToTensorV2 as ToTensor\n","\n","import random"]},{"cell_type":"markdown","metadata":{"id":"EXODz3-x_22b"},"source":["### DatasetとDataloaderの作成"]},{"cell_type":"code","source":["#GPUを使う\n","cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","#Google ドライブのファイルに連携\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjkIeeW2F7KS","executionInfo":{"status":"ok","timestamp":1688032967330,"user_tz":-540,"elapsed":25928,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}},"outputId":"1efe0f3a-5bce-48f2-db8f-4f013f0baf2b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"9oa6zG3L_22b","executionInfo":{"status":"ok","timestamp":1688032967333,"user_tz":-540,"elapsed":20,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["#それぞれのパス\n","DATA_TRAIN_img_ROOT = \"/content/drive/MyDrive/Ntask/task/dataset/Train/Images\"\n","DATA_TRAIN_seg_ROOT = \"/content/drive/MyDrive/Ntask/task//dataset/Train/Segmentations\"\n","\n","DATA_VALID_img_ROOT = \"/content/drive/MyDrive/Ntask/task//dataset/Valid/Images\"\n","DATA_VALID_seg_ROOT = \"/content/drive/MyDrive/Ntask/task//dataset/Valid/Segmentations\"\n","\n","DATA_TEST_img_ROOT = \"/content/drive/MyDrive/Ntask/task//dataset/Test/Images\"\n","DATA_TEST_seg_ROOT = \"/content/drive/MyDrive/Ntask/task//dataset/Test/Segmentations\""]},{"cell_type":"code","source":["def path_append(path1,path2,list1):\n","  a=os.listdir(path1)\n","  a.sort()\n","  for x in a:\n","    for y in os.listdir(os.path.join(path1,x)):\n","      if len(os.listdir(os.path.join(path1,x))) == len(os.listdir(os.path.join(path2,x))):\n","         list1.append(os.path.join(path1,x,y))\n","         list1.sort()"],"metadata":{"id":"apaPTsyLGPPq","executionInfo":{"status":"ok","timestamp":1688032967334,"user_tz":-540,"elapsed":19,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_img_path = []\n","train_seg_path = []\n","\n","valid_img_path=[]\n","valid_seg_path=[]\n","\n","test_img_path=[]\n","test_seg_path=[]"],"metadata":{"id":"e0n4c-a1H7OS","executionInfo":{"status":"ok","timestamp":1688032967335,"user_tz":-540,"elapsed":19,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#訓練、バリデーション、テスト、それぞれのパスを取得\n","path_append(DATA_TRAIN_img_ROOT,DATA_TRAIN_seg_ROOT,train_img_path)\n","path_append(DATA_TRAIN_seg_ROOT,DATA_TRAIN_img_ROOT,train_seg_path)\n","\n","path_append(DATA_VALID_img_ROOT,DATA_VALID_seg_ROOT,valid_img_path)\n","path_append(DATA_VALID_seg_ROOT,DATA_VALID_img_ROOT,valid_seg_path)\n","\n","path_append(DATA_TEST_img_ROOT,DATA_TEST_seg_ROOT,test_img_path)\n","path_append(DATA_TEST_seg_ROOT,DATA_TEST_img_ROOT,test_seg_path)"],"metadata":{"id":"jGhdoD2jIG4M","executionInfo":{"status":"ok","timestamp":1688033021665,"user_tz":-540,"elapsed":54348,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#画像データ拡張の関数 *改善の余地あり\n","def get_train_transform():\n","   return A.Compose(\n","       [\n","        #正規化(albumentations.augmentations.transforms.Normalizeのデフォルトの値を適用)\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        ToTensor()\n","        ])"],"metadata":{"id":"LQIYEMNnJLid","executionInfo":{"status":"ok","timestamp":1688033021669,"user_tz":-540,"elapsed":82,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6HeQAMqI_22b","executionInfo":{"status":"ok","timestamp":1688033021670,"user_tz":-540,"elapsed":79,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["class MyDataset(Dataset):\n","\n","    def __init__(self,im_root,mask_root,transform=None):\n","      self.image_path = im_root\n","      self.mask_path = mask_root\n","      self.transforms = get_train_transform()\n","\n","    def __len__(self):\n","        return len(self.image_path)\n","\n","    def __getitem__(self, idx):\n","        #パスを取得\n","        image_path = self.image_path\n","        mask_path = self.mask_path\n","\n","        # 画像の読込\n","        img = io.imread(image_path[idx])[:,:,:3].astype(\"float32\")\n","        mask = io.imread(mask_path[idx]).astype(\"float32\")\n","        #縮小\n","        img = transform.resize(img,(256,256))\n","        mask = transform.resize(mask,(256,256))\n","\n","        #次元を合わせる\n","        mask = np.expand_dims(mask,axis=-1)\n","        mask = np.maximum(mask, np.zeros((256, 256, 1), dtype=np.bool))\n","        mask=mask.transpose(2,0,1)\n","\n","        augmented = self.transforms(image=img, mask=mask)\n","        img = augmented['image']\n","        mask = augmented['mask']\n","        return (img,mask)\n","\n","train_dataset = MyDataset(train_img_path,train_seg_path,transform=get_train_transform())\n","valid_dataset=MyDataset(valid_img_path,valid_seg_path,transform=get_train_transform())\n","test_dataset=MyDataset(test_img_path,test_seg_path,transform=get_train_transform())\n"]},{"cell_type":"code","source":["train_dataloader = DataLoader(dataset=train_dataset, batch_size=30, shuffle=True)\n","valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=30, shuffle=True)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)"],"metadata":{"id":"L3h5owMgLZ82","executionInfo":{"status":"ok","timestamp":1688033021672,"user_tz":-540,"elapsed":78,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4a6ZTWL1_22c"},"source":["### セグメンテーションモデルの実装"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"RS0Rmhrf_22c","executionInfo":{"status":"ok","timestamp":1688033021673,"user_tz":-540,"elapsed":77,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["\n","class UNet(nn.Module):\n","    def __init__(self, input_channels, output_channels):\n","        super().__init__()\n","\n","        self.conv1 = conv_bn_relu(input_channels,64)\n","        self.conv2 = conv_bn_relu(64, 128)\n","        self.conv3 = conv_bn_relu(128, 256)\n","        self.conv4 = conv_bn_relu(256, 512)\n","        self.conv5 = conv_bn_relu(512, 1024)\n","        self.down_pooling = nn.MaxPool2d(2)\n","\n","        self.up_pool6 = up_pooling(1024, 512)\n","        self.conv6 = conv_bn_relu(1024, 512)\n","        self.up_pool7 = up_pooling(512, 256)\n","        self.conv7 = conv_bn_relu(512, 256)\n","        self.up_pool8 = up_pooling(256, 128)\n","        self.conv8 = conv_bn_relu(256, 128)\n","        self.up_pool9 = up_pooling(128, 64)\n","        self.conv9 = conv_bn_relu(128, 64)\n","        self.conv10 = nn.Conv2d(64, output_channels, 1)\n","\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        # 正規化\n","        x = x/255.\n","\n","\n","        x1 = self.conv1(x)\n","        p1 = self.down_pooling(x1)\n","        x2 = self.conv2(p1)\n","        p2 = self.down_pooling(x2)\n","        x3 = self.conv3(p2)\n","        p3 = self.down_pooling(x3)\n","        x4 = self.conv4(p3)\n","        p4 = self.down_pooling(x4)\n","        x5 = self.conv5(p4)\n","\n","\n","        p6 = self.up_pool6(x5)\n","        x6 = torch.cat([p6, x4], dim=1)\n","        x6 = self.conv6(x6)\n","\n","        p7 = self.up_pool7(x6)\n","        x7 = torch.cat([p7, x3], dim=1)\n","        x7 = self.conv7(x7)\n","\n","        p8 = self.up_pool8(x7)\n","        x8 = torch.cat([p8, x2], dim=1)\n","        x8 = self.conv8(x8)\n","\n","        p9 = self.up_pool9(x8)\n","        x9 = torch.cat([p9, x1], dim=1)\n","        x9 = self.conv9(x9)\n","\n","\n","        output = self.conv10(x9)\n","        output = torch.sigmoid(output)\n","\n","        return output\n","\n","#畳み込みとバッチ正規化と活性化関数Reluをまとめている\n","def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n","    return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            Dropout(0.02)\n","    )\n","\n","def down_pooling():\n","    return nn.MaxPool2d(2)\n","\n","def up_pooling(in_channels, out_channels, kernel_size=2, stride=2):\n","    return nn.Sequential(\n","        #転置畳み込み\n","        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True)\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"VZ9U3wG-_22c"},"source":["- モデルの引用"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"iYolX5dD_22d","executionInfo":{"status":"ok","timestamp":1688033021675,"user_tz":-540,"elapsed":78,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["\n","random_state = 42\n","random.seed(random_state)\n","np.random.RandomState(random_state)\n","torch.manual_seed(random_state)\n","torch.cuda.manual_seed(random_state)\n","\n"]},{"cell_type":"markdown","source":["###損失関数の定義"],"metadata":{"id":"FZUtSMDUMgY-"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"YiVLfLPPiBF7","executionInfo":{"status":"ok","timestamp":1688033021677,"user_tz":-540,"elapsed":79,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[],"source":["class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceBCELoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)\n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n","        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","\n","        return Dice_BCE\n","\n","\n","class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = F.sigmoid(inputs)\n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n","\n","        return 1 - dice"]},{"cell_type":"markdown","source":["###IoUの定義"],"metadata":{"id":"xDmUire5M6m8"}},{"cell_type":"code","source":["class IoU(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(IoU, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        intersection = (inputs * targets).sum()\n","        total = (inputs + targets).sum()\n","        union = total - intersection\n","\n","        IoU = (intersection + smooth)/(union + smooth)\n","\n","        return IoU"],"metadata":{"id":"n8gW21UiM8HU","executionInfo":{"status":"ok","timestamp":1688033021678,"user_tz":-540,"elapsed":78,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e70vB9MZ_22d"},"source":["### モデルトレーニング"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"id":"jbZ4cXBS_22d","outputId":"f4b5dee4-b4bc-405b-9aa2-f0c465d02e1b","executionInfo":{"status":"error","timestamp":1688033090281,"user_tz":-540,"elapsed":68679,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\rdescription:   0%|          | 0/26 [00:00<?, ?it/s]<ipython-input-8-12e26c5a0049>:25: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  mask = np.maximum(mask, np.zeros((256, 256, 1), dtype=np.bool))\n","description:   0%|          | 0/26 [01:03<?, ?it/s]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-531b72f83867>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# 損失計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-c7dd80a06883>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mp9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_pool9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 14.75 GiB total capacity; 13.26 GiB already allocated; 128.81 MiB free; 13.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["#Google colaboratoryで実行\n","#ランタイム→ランタイムのタイプを変更→NoneからGPUに変更\n","\n","model = UNet(3,1).cuda()\n","num_epochs=20\n","\n","optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)\n","criterion = DiceLoss()\n","accuracy_metric = IoU()\n","valid_loss_min = np.Inf\n","\n","\n","total_train_loss = []\n","total_train_score = []\n","total_valid_loss = []\n","total_valid_score = []\n","\n","losses_value = 0\n","\n","for epoch in range(num_epochs):\n","  #<---------------トレーニング---------------------->\n","    train_loss = []\n","    train_score = []\n","    valid_loss = []\n","    valid_score = []\n","    pbar = tqdm(train_dataloader, desc = 'description')\n","\n","    for x_train, y_train in pbar:\n","      x_train = torch.autograd.Variable(x_train).cuda()\n","      y_train = torch.autograd.Variable(y_train).cuda()\n","      optimizer.zero_grad()\n","      output = model(x_train)\n","\n","      # 損失計算\n","      loss = criterion(output, y_train)\n","      losses_value = loss.item()\n","\n","      # 精度評価\n","      score = accuracy_metric(output,y_train)\n","      loss.backward()\n","      optimizer.step()\n","      train_loss.append(losses_value)\n","      train_score.append(score.item())\n","      pbar.set_description(f\"Epoch: {epoch+1}, loss: {losses_value}, IoU: {score}\")\n","\n","    #<---------------評価---------------------->\n","    with torch.no_grad():\n","      for image,mask in valid_dataloader:\n","        image = torch.autograd.Variable(image).cuda()\n","        mask = torch.autograd.Variable(mask).cuda()\n","        output = model(image)\n","        ## 損失計算\n","        loss = criterion(output, mask)\n","        losses_value = loss.item()\n","        ## 精度評価\n","        score = accuracy_metric(output,mask)\n","        valid_loss.append(losses_value)\n","        valid_score.append(score.item())\n","\n","    total_train_loss.append(np.mean(train_loss))\n","    total_train_score.append(np.mean(train_score))\n","    total_valid_loss.append(np.mean(valid_loss))\n","    total_valid_score.append(np.mean(valid_score))\n","\n","    print(f\"Train Loss: {total_train_loss[-1]}, Train IoU: {total_train_score[-1]}\")\n","    print(f\"Valid Loss: {total_valid_loss[-1]}, Valid IoU: {total_valid_score[-1]}\")\n","\n","\n","    if total_valid_loss[-1] <= valid_loss_min:\n","      best_model=model\n","\n","    print(\"\")\n"]},{"cell_type":"code","source":["#学習率を下げて再度学習\n","optimizer = torch.optim.Adam(model.parameters(),lr = 1e-4)\n","for epoch in range(20,35):\n","  #<---------------トレーニング---------------------->\n","    train_loss = []\n","    train_score = []\n","    valid_loss = []\n","    valid_score = []\n","    pbar = tqdm(train_dataloader, desc = 'description')\n","\n","    for x_train, y_train in pbar:\n","      x_train = torch.autograd.Variable(x_train).cuda()\n","      y_train = torch.autograd.Variable(y_train).cuda()\n","      optimizer.zero_grad()\n","      output = model(x_train)\n","      # 損失計算\n","      loss = criterion(output, y_train)\n","      losses_value = loss.item()\n","      # 精度評価\n","      score = accuracy_metric(output,y_train)\n","      loss.backward()\n","      optimizer.step()\n","      train_loss.append(losses_value)\n","      train_score.append(score.item())\n","      pbar.set_description(f\"Epoch: {epoch+1}, loss: {losses_value}, IoU: {score}\")\n","\n","    #<---------------評価---------------------->\n","    with torch.no_grad():\n","      for image,mask in valid_dataloader:\n","        image = torch.autograd.Variable(image).cuda()\n","        mask = torch.autograd.Variable(mask).cuda()\n","        output = model(image)\n","        ## 損失計算\n","        loss = criterion(output, mask)\n","        losses_value = loss.item()\n","        ## 精度評価\n","        score = accuracy_metric(output,mask)\n","        valid_loss.append(losses_value)\n","        valid_score.append(score.item())\n","\n","    total_train_loss.append(np.mean(train_loss))\n","    total_train_score.append(np.mean(train_score))\n","    total_valid_loss.append(np.mean(valid_loss))\n","    total_valid_score.append(np.mean(valid_score))\n","\n","    print(f\"Train Loss: {total_train_loss[-1]}, Train IoU: {total_train_score[-1]}\")\n","    print(f\"Valid Loss: {total_valid_loss[-1]}, Valid IoU: {total_valid_score[-1]}\")\n","\n","\n","\n","    print(\"\")\n"],"metadata":{"id":"i3_SgcW9OlRM","executionInfo":{"status":"aborted","timestamp":1688033090291,"user_tz":-540,"elapsed":35,"user":{"displayName":"八幡光祈","userId":"10698955805104324319"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"aaa572785d50ca385bbbdf49e5d055024fc470a6b45bad620570f0d05268d6f7"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}